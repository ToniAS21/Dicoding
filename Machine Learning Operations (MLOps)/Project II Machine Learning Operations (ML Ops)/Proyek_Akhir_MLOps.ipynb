{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prediction Potensial Customer"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cB-ddGEaGJui",
        "outputId": "f27063e1-211d-45dd-89ac-d91524a0f68e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tfx in /usr/local/lib/python3.8/dist-packages (1.12.0)\n",
            "Requirement already satisfied: tensorflow_model_analysis in /usr/local/lib/python3.8/dist-packages (0.43.0)\n",
            "Requirement already satisfied: grpcio<2,>=1.28.1 in /usr/local/lib/python3.8/dist-packages (from tfx) (1.51.1)\n",
            "Requirement already satisfied: tfx-bsl<1.13.0,>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tfx) (1.12.0)\n",
            "Requirement already satisfied: numpy<2,>=1.16 in /usr/local/lib/python3.8/dist-packages (from tfx) (1.21.6)\n",
            "Requirement already satisfied: protobuf<4,>=3.13 in /usr/local/lib/python3.8/dist-packages (from tfx) (3.19.6)\n",
            "Requirement already satisfied: jinja2<4,>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from tfx) (2.11.3)\n",
            "Requirement already satisfied: apache-beam[gcp]<3,>=2.40 in /usr/local/lib/python3.8/dist-packages (from tfx) (2.43.0)\n",
            "Requirement already satisfied: google-apitools<1,>=0.5 in /usr/local/lib/python3.8/dist-packages (from tfx) (0.5.31)\n",
            "Requirement already satisfied: google-api-python-client<2,>=1.8 in /usr/local/lib/python3.8/dist-packages (from tfx) (1.12.11)\n",
            "Requirement already satisfied: absl-py<2.0.0,>=0.9 in /usr/local/lib/python3.8/dist-packages (from tfx) (1.3.0)\n",
            "Requirement already satisfied: google-cloud-aiplatform<1.18,>=1.6.2 in /usr/local/lib/python3.8/dist-packages (from tfx) (1.17.1)\n",
            "Requirement already satisfied: docker<5,>=4.1 in /usr/local/lib/python3.8/dist-packages (from tfx) (4.4.4)\n",
            "Requirement already satisfied: click<8,>=7 in /usr/local/lib/python3.8/dist-packages (from tfx) (7.1.2)\n",
            "Requirement already satisfied: portpicker<2,>=1.3.1 in /usr/local/lib/python3.8/dist-packages (from tfx) (1.3.9)\n",
            "Requirement already satisfied: ml-metadata<1.13.0,>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tfx) (1.12.0)\n",
            "Requirement already satisfied: kubernetes<13,>=10.0.1 in /usr/local/lib/python3.8/dist-packages (from tfx) (12.0.1)\n",
            "Requirement already satisfied: packaging<21,>=20 in /usr/local/lib/python3.8/dist-packages (from tfx) (20.9)\n",
            "Requirement already satisfied: tensorflow-serving-api!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15 in /usr/local/lib/python3.8/dist-packages (from tfx) (2.11.0)\n",
            "Requirement already satisfied: google-cloud-bigquery<3,>=2.26.0 in /usr/local/lib/python3.8/dist-packages (from tfx) (2.34.4)\n",
            "Requirement already satisfied: attrs<22,>=19.3.0 in /usr/local/lib/python3.8/dist-packages (from tfx) (21.4.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=3.10.0.2 in /usr/local/lib/python3.8/dist-packages (from tfx) (4.4.0)\n",
            "Requirement already satisfied: tensorflow-hub<0.13,>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from tfx) (0.12.0)\n",
            "Requirement already satisfied: pyyaml<6,>=3.12 in /usr/local/lib/python3.8/dist-packages (from tfx) (5.4.1)\n",
            "Requirement already satisfied: tensorflow-data-validation<1.13.0,>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tfx) (1.12.0)\n",
            "Requirement already satisfied: ml-pipelines-sdk==1.12.0 in /usr/local/lib/python3.8/dist-packages (from tfx) (1.12.0)\n",
            "Requirement already satisfied: pyarrow<7,>=6 in /usr/local/lib/python3.8/dist-packages (from tfx) (6.0.1)\n",
            "Requirement already satisfied: tensorflow-transform<1.13.0,>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tfx) (1.12.0)\n",
            "Requirement already satisfied: tensorflow<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tfx) (2.11.0)\n",
            "Requirement already satisfied: keras-tuner<2,>=1.0.4 in /usr/local/lib/python3.8/dist-packages (from tfx) (1.1.3)\n",
            "Requirement already satisfied: google-api-core<1.33 in /usr/local/lib/python3.8/dist-packages (from tfx) (1.32.0)\n",
            "Requirement already satisfied: scipy<2,>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow_model_analysis) (1.7.3)\n",
            "Requirement already satisfied: tensorflow-metadata<1.13.0,>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_model_analysis) (1.12.0)\n",
            "Requirement already satisfied: six<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow_model_analysis) (1.15.0)\n",
            "Requirement already satisfied: ipython<8,>=7 in /usr/local/lib/python3.8/dist-packages (from tensorflow_model_analysis) (7.9.0)\n",
            "Requirement already satisfied: ipywidgets<8,>=7 in /usr/local/lib/python3.8/dist-packages (from tensorflow_model_analysis) (7.7.1)\n",
            "Requirement already satisfied: pandas<2,>=1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_model_analysis) (1.3.5)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]<3,>=2.40->tfx) (2.8.2)\n",
            "Requirement already satisfied: regex>=2020.6.8 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]<3,>=2.40->tfx) (2022.6.2)\n",
            "Requirement already satisfied: fastavro<2,>=0.23.6 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]<3,>=2.40->tfx) (1.7.0)\n",
            "Requirement already satisfied: objsize<0.6.0,>=0.5.2 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]<3,>=2.40->tfx) (0.5.2)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]<3,>=2.40->tfx) (1.3.0)\n",
            "Requirement already satisfied: cloudpickle~=2.2.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]<3,>=2.40->tfx) (2.2.0)\n",
            "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]<3,>=2.40->tfx) (3.13.0)\n",
            "Requirement already satisfied: orjson<4.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]<3,>=2.40->tfx) (3.8.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]<3,>=2.40->tfx) (2.25.1)\n",
            "Requirement already satisfied: fasteners<1.0,>=0.3 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]<3,>=2.40->tfx) (0.18)\n",
            "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]<3,>=2.40->tfx) (0.3.1.1)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]<3,>=2.40->tfx) (1.22.1)\n",
            "Requirement already satisfied: httplib2<0.21.0,>=0.8 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]<3,>=2.40->tfx) (0.17.4)\n",
            "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]<3,>=2.40->tfx) (2.7.0)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]<3,>=2.40->tfx) (2022.7)\n",
            "Requirement already satisfied: zstandard<1,>=0.18.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]<3,>=2.40->tfx) (0.19.0)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]<3,>=2.40->tfx) (1.7)\n",
            "Requirement already satisfied: google-cloud-pubsub<3,>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]<3,>=2.40->tfx) (2.13.11)\n",
            "Requirement already satisfied: google-cloud-language<2,>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]<3,>=2.40->tfx) (1.3.2)\n",
            "Requirement already satisfied: google-cloud-spanner<4,>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]<3,>=2.40->tfx) (3.26.0)\n",
            "Requirement already satisfied: cachetools<5,>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]<3,>=2.40->tfx) (4.2.4)\n",
            "Requirement already satisfied: google-cloud-videointelligence<2,>=1.8.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]<3,>=2.40->tfx) (1.16.3)\n",
            "Requirement already satisfied: google-cloud-core<3,>=0.28.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]<3,>=2.40->tfx) (2.3.2)\n",
            "Requirement already satisfied: google-cloud-recommendations-ai<0.8.0,>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]<3,>=2.40->tfx) (0.7.1)\n",
            "Requirement already satisfied: google-cloud-datastore<2,>=1.8.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]<3,>=2.40->tfx) (1.15.5)\n",
            "Requirement already satisfied: google-cloud-dlp<4,>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]<3,>=2.40->tfx) (3.9.2)\n",
            "Requirement already satisfied: google-auth-httplib2<0.2.0,>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]<3,>=2.40->tfx) (0.1.0)\n",
            "Requirement already satisfied: google-cloud-vision<2,>=0.38.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]<3,>=2.40->tfx) (1.0.2)\n",
            "Requirement already satisfied: google-cloud-bigtable<2,>=0.31.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]<3,>=2.40->tfx) (1.7.3)\n",
            "Requirement already satisfied: google-cloud-pubsublite<2,>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]<3,>=2.40->tfx) (1.6.0)\n",
            "Requirement already satisfied: google-cloud-bigquery-storage<2.14,>=2.6.3 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]<3,>=2.40->tfx) (2.13.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.18.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]<3,>=2.40->tfx) (1.35.0)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.8/dist-packages (from docker<5,>=4.1->tfx) (1.4.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from google-api-core<1.33->tfx) (1.57.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.8/dist-packages (from google-api-core<1.33->tfx) (57.4.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client<2,>=1.8->tfx) (3.0.1)\n",
            "Requirement already satisfied: oauth2client>=1.4.12 in /usr/local/lib/python3.8/dist-packages (from google-apitools<1,>=0.5->tfx) (4.1.3)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.8/dist-packages (from google-cloud-aiplatform<1.18,>=1.6.2->tfx) (2.7.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.8/dist-packages (from google-cloud-aiplatform<1.18,>=1.6.2->tfx) (1.6.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from google-cloud-bigquery<3,>=2.26.0->tfx) (2.4.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython<8,>=7->tensorflow_model_analysis) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython<8,>=7->tensorflow_model_analysis) (2.0.10)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython<8,>=7->tensorflow_model_analysis) (0.2.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython<8,>=7->tensorflow_model_analysis) (2.6.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython<8,>=7->tensorflow_model_analysis) (4.8.0)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.8/dist-packages (from ipython<8,>=7->tensorflow_model_analysis) (0.18.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython<8,>=7->tensorflow_model_analysis) (4.4.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython<8,>=7->tensorflow_model_analysis) (5.7.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets<8,>=7->tensorflow_model_analysis) (3.0.5)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets<8,>=7->tensorflow_model_analysis) (0.2.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.8/dist-packages (from ipywidgets<8,>=7->tensorflow_model_analysis) (5.3.4)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets<8,>=7->tensorflow_model_analysis) (3.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2<4,>=2.7.3->tfx) (2.0.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.8/dist-packages (from keras-tuner<2,>=1.0.4->tfx) (2.11.0)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.8/dist-packages (from keras-tuner<2,>=1.0.4->tfx) (1.0.4)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.8/dist-packages (from kubernetes<13,>=10.0.1->tfx) (2022.12.7)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.8/dist-packages (from kubernetes<13,>=10.0.1->tfx) (1.24.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.8/dist-packages (from kubernetes<13,>=10.0.1->tfx) (1.3.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging<21,>=20->tfx) (3.0.9)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tfx) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tfx) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tfx) (23.1.4)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tfx) (0.29.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tfx) (2.11.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tfx) (1.6.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tfx) (0.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tfx) (3.1.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tfx) (2.11.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tfx) (1.14.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tfx) (14.0.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tfx) (2.1.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-data-validation<1.13.0,>=1.12.0->tfx) (1.2.0)\n",
            "Requirement already satisfied: pyfarmhash<0.4,>=0.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow-data-validation<1.13.0,>=1.12.0->tfx) (0.3.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow<2.12,>=2.11.0->tfx) (0.38.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.40->tfx) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.40->tfx) (0.2.8)\n",
            "Requirement already satisfied: grpc-google-iam-v1<0.13dev,>=0.12.3 in /usr/local/lib/python3.8/dist-packages (from google-cloud-bigtable<2,>=0.31.1->apache-beam[gcp]<3,>=2.40->tfx) (0.12.4)\n",
            "Requirement already satisfied: grpcio-status>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.40->tfx) (1.48.2)\n",
            "Requirement already satisfied: overrides<7.0.0,>=6.0.1 in /usr/local/lib/python3.8/dist-packages (from google-cloud-pubsublite<2,>=1.2.0->apache-beam[gcp]<3,>=2.40->tfx) (6.5.0)\n",
            "Requirement already satisfied: sqlparse>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from google-cloud-spanner<4,>=3.0.0->apache-beam[gcp]<3,>=2.40->tfx) (0.4.3)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.8/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3,>=2.26.0->tfx) (1.5.0)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.8/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.40->tfx) (0.6.2)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow_model_analysis) (6.0.4)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow_model_analysis) (6.1.12)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython<8,>=7->tensorflow_model_analysis) (0.8.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.8/dist-packages (from oauth2client>=1.4.12->google-apitools<1,>=0.5->tfx) (0.4.8)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython<8,>=7->tensorflow_model_analysis) (0.2.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.40->tfx) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.40->tfx) (4.0.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner<2,>=1.0.4->tfx) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner<2,>=1.0.4->tfx) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner<2,>=1.0.4->tfx) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner<2,>=1.0.4->tfx) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner<2,>=1.0.4->tfx) (0.6.1)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.8/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow_model_analysis) (5.7.16)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython<8,>=7->tensorflow_model_analysis) (0.7.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib->kubernetes<13,>=10.0.1->tfx) (3.2.2)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner<2,>=1.0.4->tfx) (5.2.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow_model_analysis) (0.13.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow_model_analysis) (1.8.0)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow_model_analysis) (5.1.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow_model_analysis) (0.15.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow_model_analysis) (5.7.1)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow_model_analysis) (23.2.1)\n",
            "Requirement already satisfied: nbconvert<6.0 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow_model_analysis) (5.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner<2,>=1.0.4->tfx) (3.11.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core>=4.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow_model_analysis) (2.6.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow_model_analysis) (1.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow_model_analysis) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow_model_analysis) (0.8.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow_model_analysis) (0.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow_model_analysis) (0.6.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow_model_analysis) (5.0.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow_model_analysis) (2.16.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.8/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow_model_analysis) (4.3.3)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow_model_analysis) (0.19.2)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow_model_analysis) (5.10.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.8/dist-packages (from bleach->nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow_model_analysis) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install tfx tensorflow_model_analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ho1Lz6d44QJS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow_model_analysis as tfma\n",
        "from tfx.types import Channel\n",
        "from tfx.dsl.components.common.resolver import Resolver\n",
        "from tfx.types.standard_artifacts import Model, ModelBlessing\n",
        "from tfx.proto import example_gen_pb2, trainer_pb2, pusher_pb2\n",
        "from tfx.components import Transform, Trainer, Tuner, Evaluator, Pusher\n",
        "from tfx.components import CsvExampleGen, StatisticsGen, SchemaGen, ExampleValidator\n",
        "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
        "from tfx.dsl.input_resolution.strategies.latest_blessed_model_strategy import LatestBlessedModelStrategy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MQ2UpGdJNsG"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFT-z5dhJMjy",
        "outputId": "4bbda3a1-8baf-49ce-affa-51f8e29702ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/data.zip\n",
            "replace data/bank-marketing.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ]
        }
      ],
      "source": [
        "!unzip '/content/data.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "wf3yfE9QJWNz",
        "outputId": "c6ab0cd8-f469-4d8e-defb-74e73861c408"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-eb35e6cf-54fb-4afd-9e96-7f58f92568ed\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>age group</th>\n",
              "      <th>eligible</th>\n",
              "      <th>job</th>\n",
              "      <th>salary</th>\n",
              "      <th>marital</th>\n",
              "      <th>education</th>\n",
              "      <th>marital-education</th>\n",
              "      <th>targeted</th>\n",
              "      <th>default</th>\n",
              "      <th>...</th>\n",
              "      <th>contact</th>\n",
              "      <th>day</th>\n",
              "      <th>month</th>\n",
              "      <th>duration</th>\n",
              "      <th>campaign</th>\n",
              "      <th>pdays</th>\n",
              "      <th>previous</th>\n",
              "      <th>poutcome</th>\n",
              "      <th>y</th>\n",
              "      <th>response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>58</td>\n",
              "      <td>5</td>\n",
              "      <td>Y</td>\n",
              "      <td>management</td>\n",
              "      <td>100000</td>\n",
              "      <td>married</td>\n",
              "      <td>tertiary</td>\n",
              "      <td>married-tertiary</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>...</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>261</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>44</td>\n",
              "      <td>4</td>\n",
              "      <td>Y</td>\n",
              "      <td>technician</td>\n",
              "      <td>60000</td>\n",
              "      <td>single</td>\n",
              "      <td>secondary</td>\n",
              "      <td>single-secondary</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>...</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>151</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>33</td>\n",
              "      <td>3</td>\n",
              "      <td>Y</td>\n",
              "      <td>entrepreneur</td>\n",
              "      <td>120000</td>\n",
              "      <td>married</td>\n",
              "      <td>secondary</td>\n",
              "      <td>married-secondary</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>...</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>76</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>47</td>\n",
              "      <td>4</td>\n",
              "      <td>Y</td>\n",
              "      <td>blue-collar</td>\n",
              "      <td>20000</td>\n",
              "      <td>married</td>\n",
              "      <td>unknown</td>\n",
              "      <td>married-unknown</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>...</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>92</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>33</td>\n",
              "      <td>3</td>\n",
              "      <td>Y</td>\n",
              "      <td>unknown</td>\n",
              "      <td>0</td>\n",
              "      <td>single</td>\n",
              "      <td>unknown</td>\n",
              "      <td>single-unknown</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>...</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>198</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 23 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb35e6cf-54fb-4afd-9e96-7f58f92568ed')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eb35e6cf-54fb-4afd-9e96-7f58f92568ed button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eb35e6cf-54fb-4afd-9e96-7f58f92568ed');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   age  age group eligible           job  salary  marital  education  \\\n",
              "0   58          5        Y    management  100000  married   tertiary   \n",
              "1   44          4        Y    technician   60000   single  secondary   \n",
              "2   33          3        Y  entrepreneur  120000  married  secondary   \n",
              "3   47          4        Y   blue-collar   20000  married    unknown   \n",
              "4   33          3        Y       unknown       0   single    unknown   \n",
              "\n",
              "   marital-education targeted default  ...  contact day month duration  \\\n",
              "0   married-tertiary      yes      no  ...  unknown   5   may      261   \n",
              "1   single-secondary      yes      no  ...  unknown   5   may      151   \n",
              "2  married-secondary      yes      no  ...  unknown   5   may       76   \n",
              "3    married-unknown       no      no  ...  unknown   5   may       92   \n",
              "4     single-unknown       no      no  ...  unknown   5   may      198   \n",
              "\n",
              "   campaign pdays  previous  poutcome   y  response  \n",
              "0         1    -1         0   unknown  no         0  \n",
              "1         1    -1         0   unknown  no         0  \n",
              "2         1    -1         0   unknown  no         0  \n",
              "3         1    -1         0   unknown  no         0  \n",
              "4         1    -1         0   unknown  no         0  \n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('/content/data/bank-marketing.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2gwk0m4K7Yl",
        "outputId": "7dbc944b-0cf9-49c1-d212-a19d2cd6a000"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 45211 entries, 0 to 45210\n",
            "Data columns (total 23 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   age                45211 non-null  int64 \n",
            " 1   age group          45211 non-null  int64 \n",
            " 2   eligible           45211 non-null  object\n",
            " 3   job                45211 non-null  object\n",
            " 4   salary             45211 non-null  int64 \n",
            " 5   marital            45211 non-null  object\n",
            " 6   education          45211 non-null  object\n",
            " 7   marital-education  45211 non-null  object\n",
            " 8   targeted           45211 non-null  object\n",
            " 9   default            45211 non-null  object\n",
            " 10  balance            45211 non-null  int64 \n",
            " 11  housing            45211 non-null  object\n",
            " 12  loan               45211 non-null  object\n",
            " 13  contact            45211 non-null  object\n",
            " 14  day                45211 non-null  int64 \n",
            " 15  month              45211 non-null  object\n",
            " 16  duration           45211 non-null  int64 \n",
            " 17  campaign           45211 non-null  int64 \n",
            " 18  pdays              45211 non-null  int64 \n",
            " 19  previous           45211 non-null  int64 \n",
            " 20  poutcome           45211 non-null  object\n",
            " 21  y                  45211 non-null  object\n",
            " 22  response           45211 non-null  int64 \n",
            "dtypes: int64(10), object(13)\n",
            "memory usage: 7.9+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6RtEMcTJVL8"
      },
      "source": [
        "## Components.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HTmZAlAxJnog"
      },
      "outputs": [],
      "source": [
        "# Mendefinisikan nama module \n",
        "COMPONENTS_MODULE_FILE = 'modules/components.py'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peNGECkNJnvm",
        "outputId": "c5661566-d8a2-40c5-a575-4a083b569d28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting modules/components.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile {COMPONENTS_MODULE_FILE}\n",
        "\n",
        "import os\n",
        "\n",
        "import tensorflow_model_analysis as tfma\n",
        "from tfx.components import (CsvExampleGen, Evaluator, ExampleValidator, Pusher,\n",
        "                            SchemaGen, StatisticsGen, Trainer, Transform,\n",
        "                            Tuner)\n",
        "from tfx.dsl.components.common.resolver import Resolver\n",
        "from tfx.dsl.input_resolution.strategies.latest_blessed_model_strategy import \\\n",
        "    LatestBlessedModelStrategy\n",
        "from tfx.proto import example_gen_pb2, pusher_pb2, trainer_pb2\n",
        "from tfx.types import Channel\n",
        "from tfx.types.standard_artifacts import Model, ModelBlessing\n",
        "\n",
        "\n",
        "def init_components(args):\n",
        "    \"\"\"Initiate tfx pipeline components\n",
        "\n",
        "    Args:\n",
        "        args (dict): args that containts some dependencies\n",
        "\n",
        "    Returns:\n",
        "        tuple: TFX pipeline components\n",
        "    \"\"\"\n",
        "    output = example_gen_pb2.Output(\n",
        "        split_config=example_gen_pb2.SplitConfig(splits=[\n",
        "            example_gen_pb2.SplitConfig.Split(name=\"train\", hash_buckets=8),\n",
        "            example_gen_pb2.SplitConfig.Split(name=\"eval\", hash_buckets=2),\n",
        "        ])\n",
        "    )\n",
        "\n",
        "    example_gen = CsvExampleGen(\n",
        "        input_base=args[\"data_dir\"],\n",
        "        output_config=output,\n",
        "    )\n",
        "\n",
        "    statistics_gen = StatisticsGen(\n",
        "        examples=example_gen.outputs[\"examples\"],\n",
        "    )\n",
        "\n",
        "    schema_gen = SchemaGen(\n",
        "        statistics=statistics_gen.outputs[\"statistics\"],\n",
        "    )\n",
        "\n",
        "    example_validator = ExampleValidator(\n",
        "        statistics=statistics_gen.outputs[\"statistics\"],\n",
        "        schema=schema_gen.outputs[\"schema\"],\n",
        "    )\n",
        "\n",
        "    transform = Transform(\n",
        "        examples=example_gen.outputs[\"examples\"],\n",
        "        schema=schema_gen.outputs[\"schema\"],\n",
        "        module_file=os.path.abspath(args[\"transform_module\"]),\n",
        "    )\n",
        "\n",
        "    tuner = Tuner(\n",
        "        module_file=os.path.abspath(args[\"tuner_module\"]),\n",
        "        examples=transform.outputs[\"transformed_examples\"],\n",
        "        transform_graph=transform.outputs[\"transform_graph\"],\n",
        "        schema=schema_gen.outputs[\"schema\"],\n",
        "        train_args=trainer_pb2.TrainArgs(\n",
        "            splits=[\"train\"],\n",
        "            num_steps=args[\"train_steps\"],\n",
        "        ),\n",
        "        eval_args=trainer_pb2.EvalArgs(\n",
        "            splits=[\"eval\"],\n",
        "            num_steps=args[\"eval_steps\"],\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        module_file=args[\"trainer_module\"],\n",
        "        examples=transform.outputs[\"transformed_examples\"],\n",
        "        transform_graph=transform.outputs[\"transform_graph\"],\n",
        "        schema=schema_gen.outputs[\"schema\"],\n",
        "        hyperparameters=tuner.outputs[\"best_hyperparameters\"],\n",
        "        train_args=trainer_pb2.TrainArgs(\n",
        "            splits=[\"train\"],\n",
        "            num_steps=args[\"train_steps\"],\n",
        "        ),\n",
        "        eval_args=trainer_pb2.EvalArgs(\n",
        "            splits=[\"eval\"],\n",
        "            num_steps=args[\"eval_steps\"]\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    model_resolver = Resolver(\n",
        "        strategy_class=LatestBlessedModelStrategy,\n",
        "        model=Channel(type=Model),\n",
        "        model_blessing=Channel(type=ModelBlessing),\n",
        "    ).with_id(\"Latest_blessed_model_resolve\")\n",
        "\n",
        "    eval_config = tfma.EvalConfig(\n",
        "        model_specs=[tfma.ModelSpec(label_key=\"response\")],\n",
        "        slicing_specs=[\n",
        "            tfma.SlicingSpec()#,\n",
        "            #tfma.SlicingSpec(feature_keys=[\"targeted\"]),\n",
        "        ],\n",
        "        metrics_specs=[\n",
        "            tfma.MetricsSpec(metrics=[\n",
        "                tfma.MetricConfig(class_name=\"AUC\"),\n",
        "                tfma.MetricConfig(class_name=\"Precision\"),\n",
        "                tfma.MetricConfig(class_name=\"Recall\"),\n",
        "                tfma.MetricConfig(class_name=\"ExampleCount\"),\n",
        "                tfma.MetricConfig(class_name=\"TruePositives\"),\n",
        "                tfma.MetricConfig(class_name=\"FalsePositives\"),\n",
        "                tfma.MetricConfig(class_name=\"TrueNegatives\"),\n",
        "                tfma.MetricConfig(class_name=\"FalseNegatives\"),\n",
        "                tfma.MetricConfig(\n",
        "                    class_name=\"BinaryAccuracy\",\n",
        "                    threshold=tfma.MetricThreshold(\n",
        "                        value_threshold=tfma.GenericValueThreshold(\n",
        "                            lower_bound={\"value\": .6},\n",
        "                        ),\n",
        "                        change_threshold=tfma.GenericChangeThreshold(\n",
        "                            direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n",
        "                            absolute={\"value\": 1e-4},\n",
        "                        ),\n",
        "                    ),\n",
        "                ),\n",
        "            ]),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    evaluator = Evaluator(\n",
        "        examples=example_gen.outputs[\"examples\"],\n",
        "        model=trainer.outputs[\"model\"],\n",
        "        baseline_model=model_resolver.outputs[\"model\"],\n",
        "        eval_config=eval_config,\n",
        "    )\n",
        "\n",
        "    pusher = Pusher(\n",
        "        model=trainer.outputs[\"model\"],\n",
        "        model_blessing=evaluator.outputs[\"blessing\"],\n",
        "        push_destination=pusher_pb2.PushDestination(\n",
        "            filesystem=pusher_pb2.PushDestination.Filesystem(\n",
        "                base_directory=args[\"serving_model_dir\"],\n",
        "            ),\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    return (\n",
        "        example_gen,\n",
        "        statistics_gen,\n",
        "        schema_gen,\n",
        "        example_validator,\n",
        "        transform,\n",
        "        tuner,\n",
        "        trainer,\n",
        "        model_resolver,\n",
        "        evaluator,\n",
        "        pusher,\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzZoYi9vJcP_"
      },
      "source": [
        "## Transform Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "A2JwYD13JoWa"
      },
      "outputs": [],
      "source": [
        "# Mendefinisikan nama module \n",
        "TRANSFORM_MODULE_FILE = 'modules/transform.py'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2CM08G-KJfu",
        "outputId": "5f256f52-1455-4a23-f054-487bea474de3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting modules/transform.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile {TRANSFORM_MODULE_FILE}\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_transform as tft\n",
        "\n",
        "CATEGORICAL_FEATURES = {\n",
        "    'eligible' : 2,\n",
        "    'job' : 12,\n",
        "    'marital' : 3,\n",
        "    'education'\t: 4,\n",
        "    'targeted' : 2,\n",
        "    'default' : 2,\n",
        "    'housing' : 2,\n",
        "    'loan' : 2,\n",
        "    'month' : 12\n",
        "}\n",
        "\n",
        "NUMERICAL_FEATURES = [\n",
        "    'age', \n",
        "    'salary', \n",
        "    'balance', \n",
        "    'duration', \n",
        "    'day', \n",
        "    'campaign', \n",
        "    'pdays', \n",
        "    'previous'    \n",
        "]\n",
        "\n",
        "LABEL_KEY = 'response'\n",
        "\n",
        "\n",
        "def transformed_name(key):\n",
        "    \"\"\"Transform feature key\n",
        "\n",
        "    Args:\n",
        "        key (str): the key to be transformed\n",
        "\n",
        "    Returns:\n",
        "        str: transformed key\n",
        "    \"\"\"\n",
        "\n",
        "    return f\"{key}_xf\"\n",
        "\n",
        "\n",
        "def convert_num_to_one_hot(label_tensor, num_labels=2):\n",
        "    \"\"\"Convert a label (0 or 1) into a one-hot vector\n",
        "\n",
        "    Args:\n",
        "        label_tensor (int): label tensor (0 or 1)\n",
        "        num_labels (int, optional): num of label. Defaults to 2.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: label tensor\n",
        "    \"\"\"\n",
        "\n",
        "    one_hot_tensor = tf.one_hot(label_tensor, num_labels)\n",
        "    return tf.reshape(one_hot_tensor, [-1, num_labels])\n",
        "\n",
        "\n",
        "\n",
        "def preprocessing_fn(inputs):\n",
        "    \"\"\"Preprocess input features into transformed features\n",
        "\n",
        "    Args:\n",
        "        inputs (dict): map from feature keys to raw features\n",
        "\n",
        "    Returns:\n",
        "        dict: map from features keys to transformed features\n",
        "    \"\"\"\n",
        "\n",
        "    outputs = {}\n",
        "\n",
        "    for keys, values in CATEGORICAL_FEATURES.items():\n",
        "        int_value = tft.compute_and_apply_vocabulary(\n",
        "            inputs[keys], top_k=values+1)\n",
        "        outputs[transformed_name(keys)] = convert_num_to_one_hot(\n",
        "            int_value, num_labels=values+1)\n",
        "\n",
        "    for feature in NUMERICAL_FEATURES:\n",
        "        outputs[transformed_name(feature)] = tft.scale_to_0_1(inputs[feature])\n",
        "\n",
        "    outputs[transformed_name(LABEL_KEY)] = tf.cast(inputs[LABEL_KEY], tf.int64)\n",
        "\n",
        "    return outputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veIXYg9EJf5U"
      },
      "source": [
        "## Tuner Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bB_hk5qGJo16"
      },
      "outputs": [],
      "source": [
        "# Mendefinisikan nama module \n",
        "TUNER_MODULE_FILE = 'modules/tuner.py'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Es8n21YJo4X",
        "outputId": "5c87a8e1-bf29-4a2d-8e5d-a43f3d8dddc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting modules/tuner.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile {TUNER_MODULE_FILE}\n",
        "\n",
        "from typing import Any, Dict, NamedTuple, Text\n",
        "\n",
        "import keras_tuner as kt\n",
        "import tensorflow as tf\n",
        "import tensorflow_transform as tft\n",
        "from keras import layers\n",
        "from keras_tuner.engine import base_tuner\n",
        "from transform import (CATEGORICAL_FEATURES, LABEL_KEY, NUMERICAL_FEATURES,\n",
        "                       transformed_name)\n",
        "\n",
        "NUM_EPOCHS = 5\n",
        "\n",
        "TunerFnResult = NamedTuple(\"TunerFnResult\", [\n",
        "    (\"tuner\", base_tuner.BaseTuner),\n",
        "    (\"fit_kwargs\", Dict[Text, Any]),\n",
        "])\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_binary_accuracy\",\n",
        "    mode=\"max\",\n",
        "    verbose=1,\n",
        "    patience=10,\n",
        ")\n",
        "\n",
        "\n",
        "def gzip_reader_fn(filenames):\n",
        "    \"\"\"Loads compression data\n",
        "\n",
        "    Args:\n",
        "        filenames (str): a path to the data directory\n",
        "\n",
        "    Returns:\n",
        "        TfRecord: Compressed data\n",
        "    \"\"\"\n",
        "\n",
        "    return tf.data.TFRecordDataset(filenames, compression_type=\"GZIP\")\n",
        "\n",
        "\n",
        "def input_fn(file_pattern, tf_transform_output, batch_size=64):\n",
        "    \"\"\"Generated features and labels for tuning/training\n",
        "\n",
        "    Args:\n",
        "        file_pattern: input tf_record file pattern\n",
        "        tf_transform_output: a TFTransformOutput\n",
        "        batch_size: representing the number of consecutive elements of\n",
        "        returned dataset to combine in a single batch. Defaults to 64.\n",
        "\n",
        "    Returns:\n",
        "        a dataset that contains (featurs, indices) tuple where features\n",
        "        is a dictionary of Tensors, and indices is a single Tensor of\n",
        "        label indices\n",
        "    \"\"\"\n",
        "\n",
        "    transform_feature_spec = (\n",
        "        tf_transform_output.transformed_feature_spec().copy()\n",
        "    )\n",
        "\n",
        "    dataset = tf.data.experimental.make_batched_features_dataset(\n",
        "        file_pattern=file_pattern,\n",
        "        batch_size=batch_size,\n",
        "        features=transform_feature_spec,\n",
        "        reader=gzip_reader_fn,\n",
        "        label_key=transformed_name(LABEL_KEY)\n",
        "    )\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def get_model_tuner(hyperparameters):\n",
        "    \"\"\"This function defines a keras Model\n",
        "\n",
        "    Args:\n",
        "        hyperparameters (kt.HyperParameters): object to setting hyperparameters\n",
        "\n",
        "    Returns:\n",
        "        tf.keras.Model: model as a Keras object\n",
        "    \"\"\"\n",
        "\n",
        "    num_hidden_layers = hyperparameters.Choice(\n",
        "        \"num_hidden_layers\",\n",
        "        values=[1, 2, 3],\n",
        "    )\n",
        "    dense_unit = hyperparameters.Int(\n",
        "        \"dense_unit\",\n",
        "        min_value=16,\n",
        "        max_value=512,\n",
        "        step=16,\n",
        "    )\n",
        "    dropout_rate = hyperparameters.Float(\n",
        "        \"dropout_rate\",\n",
        "        min_value=0.1,\n",
        "        max_value=0.8,\n",
        "        step=0.05,\n",
        "    )\n",
        "    learning_rate = hyperparameters.Choice(\n",
        "        \"learning_rate\",\n",
        "        values=[1e-2, 5e-3, 1e-3, 5e-4, 1e-4, 5e-5, 1e-5, 5e-6, 1.e-6]\n",
        "    )\n",
        "\n",
        "    input_features = []\n",
        "\n",
        "    for key, dim in CATEGORICAL_FEATURES.items():\n",
        "        input_features.append(\n",
        "            layers.Input(shape=(dim+1,), name=transformed_name(key))\n",
        "        )\n",
        "\n",
        "    for feature in NUMERICAL_FEATURES:\n",
        "        input_features.append(\n",
        "            layers.Input(shape=(1,), name=transformed_name(feature))\n",
        "        )\n",
        "\n",
        "    concatenate = layers.concatenate(input_features)\n",
        "    deep = layers.Dense(dense_unit, activation=tf.nn.relu)(concatenate)\n",
        "\n",
        "    for _ in range(num_hidden_layers):\n",
        "        deep = layers.Dense(dense_unit, activation=tf.nn.relu)(deep)\n",
        "        deep = layers.Dropout(dropout_rate)(deep)\n",
        "\n",
        "    outputs = layers.Dense(1, activation=tf.nn.sigmoid)(deep)\n",
        "\n",
        "    model = tf.keras.Model(inputs=input_features, outputs=outputs)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "        metrics=[\"binary_accuracy\"],\n",
        "    )\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def tuner_fn(fn_args):\n",
        "    \"\"\"Tuning the model to get the best hyperparameters based on given args\n",
        "\n",
        "    Args:\n",
        "        fn_args (FnArgs): Holds args used to train the model as name/value pair\n",
        "\n",
        "    Returns:\n",
        "        TunerFnResult (NamedTuple): object to run model tuner\n",
        "    \"\"\"\n",
        "\n",
        "    tf_transform_output = tft.TFTransformOutput(fn_args.transform_graph_path)\n",
        "\n",
        "    train_set = input_fn(fn_args.train_files[0], tf_transform_output,)\n",
        "    eval_set = input_fn(fn_args.eval_files[0], tf_transform_output,)\n",
        "\n",
        "    tuner = kt.Hyperband(\n",
        "        hypermodel=get_model_tuner,\n",
        "        objective=kt.Objective(\n",
        "            \"val_loss\",\n",
        "            direction=\"min\",\n",
        "        ),\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        factor=3,\n",
        "        directory=fn_args.working_dir,\n",
        "        project_name=\"kt_hyperband\",\n",
        "    )\n",
        "\n",
        "    return TunerFnResult(\n",
        "        tuner=tuner,\n",
        "        fit_kwargs={\n",
        "            \"x\": train_set,\n",
        "            \"validation_data\": eval_set,\n",
        "            \"steps_per_epoch\": fn_args.train_steps,\n",
        "            \"validation_steps\": fn_args.eval_steps,\n",
        "            \"callbacks\": [early_stop]\n",
        "        },\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T06xqikQJYv0"
      },
      "source": [
        "## Trainer Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "wzcwMpcRJpZx"
      },
      "outputs": [],
      "source": [
        "# Mendefinisikan nama module \n",
        "TRAINER_MODULE_FILE = 'modules/trainer.py'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32OL4xSiJpca",
        "outputId": "17750cfc-7e66-4938-b0dd-cceee55dad59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting modules/trainer.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile {TRAINER_MODULE_FILE}\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_transform as tft\n",
        "from keras import layers\n",
        "from transform import (CATEGORICAL_FEATURES, LABEL_KEY, NUMERICAL_FEATURES,\n",
        "                       transformed_name)\n",
        "from tuner import input_fn\n",
        "\n",
        "\n",
        "def get_serve_tf_examples_fn(model, tf_transform_output):\n",
        "    \"\"\"Return a function that parses a serialized tf.Example\"\"\"\n",
        "\n",
        "    model.tft_layer = tf_transform_output.transform_features_layer()\n",
        "\n",
        "    @tf.function(input_signature=[\n",
        "        tf.TensorSpec(shape=[None], dtype=tf.string, name=\"examples\"),\n",
        "    ])\n",
        "    def serve_tf_examples_fn(serialized_tf_examples):\n",
        "        \"\"\"Return the output to be used in the serving signature.\"\"\"\n",
        "\n",
        "        feature_spec = tf_transform_output.raw_feature_spec()\n",
        "        feature_spec.pop(LABEL_KEY)\n",
        "\n",
        "        parsed_features = tf.io.parse_example(\n",
        "            serialized_tf_examples, feature_spec,\n",
        "        )\n",
        "\n",
        "        transformed_features = model.tft_layer(parsed_features)\n",
        "        outputs = model(transformed_features)\n",
        "\n",
        "        return {\"outputs\": outputs}\n",
        "\n",
        "    return serve_tf_examples_fn\n",
        "\n",
        "\n",
        "def get_model(hyperparameters):\n",
        "    \"\"\"This model defines a keras Model\n",
        "\n",
        "    Args:\n",
        "        hyperparameters (kt.HyperParameters): object that contains best hyperparameters\n",
        "        from tuner\n",
        "\n",
        "    Returns:\n",
        "        tf.keras.Model: model as a Keras object\n",
        "    \"\"\"\n",
        "\n",
        "    input_features = []\n",
        "\n",
        "    for key, dim in CATEGORICAL_FEATURES.items():\n",
        "        input_features.append(\n",
        "            layers.Input(shape=(dim+1,), name=transformed_name(key))\n",
        "        )\n",
        "\n",
        "    for feature in NUMERICAL_FEATURES:\n",
        "        input_features.append(\n",
        "            layers.Input(shape=(1,), name=transformed_name(feature))\n",
        "        )\n",
        "\n",
        "    concatenate = layers.concatenate(input_features)\n",
        "    deep = layers.Dense(\n",
        "        hyperparameters[\"dense_unit\"], activation=tf.nn.relu)(concatenate)\n",
        "\n",
        "    for _ in range(hyperparameters[\"num_hidden_layers\"]):\n",
        "        deep = layers.Dense(\n",
        "            hyperparameters[\"dense_unit\"], activation=tf.nn.relu)(deep)\n",
        "        deep = layers.Dropout(hyperparameters[\"dropout_rate\"])(deep)\n",
        "\n",
        "    outputs = layers.Dense(1, activation=tf.nn.sigmoid)(deep)\n",
        "\n",
        "    model = tf.keras.Model(inputs=input_features, outputs=outputs)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(\n",
        "            learning_rate=hyperparameters[\"learning_rate\"]),\n",
        "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "        metrics=[\"binary_accuracy\"],\n",
        "    )\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def run_fn(fn_args):\n",
        "    \"\"\"Train the model based on given args\n",
        "\n",
        "    Args:\n",
        "        fn_args (FnArgs): Holds args used to train the model as name/value pairs.\n",
        "    \"\"\"\n",
        "\n",
        "    hyperparameters = fn_args.hyperparameters[\"values\"]\n",
        "    log_dir = os.path.join(os.path.dirname(fn_args.serving_model_dir), \"logs\")\n",
        "\n",
        "    tf_transform_output = tft.TFTransformOutput(fn_args.transform_output)\n",
        "\n",
        "    train_set = input_fn(fn_args.train_files, tf_transform_output)\n",
        "    eval_set = input_fn(fn_args.eval_files, tf_transform_output)\n",
        "\n",
        "    model = get_model(hyperparameters)\n",
        "\n",
        "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "        log_dir=log_dir,\n",
        "        update_freq=\"batch\"\n",
        "    )\n",
        "\n",
        "    early_stop_callbacks = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_binary_accuracy\",\n",
        "        mode=\"max\",\n",
        "        verbose=1,\n",
        "        patience=10,\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "        fn_args.serving_model_dir,\n",
        "        monitor=\"val_binary_accuracy\",\n",
        "        mode=\"max\",\n",
        "        verbose=1,\n",
        "        save_best_only=True,\n",
        "    )\n",
        "\n",
        "    callbacks = [\n",
        "        tensorboard_callback,\n",
        "        early_stop_callbacks,\n",
        "        model_checkpoint_callback\n",
        "    ]\n",
        "\n",
        "    model.fit(\n",
        "        x=train_set,\n",
        "        steps_per_epoch=fn_args.train_steps,\n",
        "        validation_data=eval_set,\n",
        "        validation_steps=fn_args.eval_steps,\n",
        "        callbacks=callbacks,\n",
        "        epochs=hyperparameters[\"tuner/initial_epoch\"],\n",
        "        verbose=1,\n",
        "    )\n",
        "\n",
        "    signatures = {\n",
        "        \"serving_default\": get_serve_tf_examples_fn(\n",
        "            model, tf_transform_output,\n",
        "        )\n",
        "    }\n",
        "\n",
        "    model.save(\n",
        "        fn_args.serving_model_dir,\n",
        "        save_format=\"tf\",\n",
        "        signatures=signatures,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ok6IDlyxJptB"
      },
      "source": [
        "## Pipeline.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-1a3b-ukKh2-"
      },
      "outputs": [],
      "source": [
        "# Mendefinisikan nama module \n",
        "PIPELINES_MODULE_FILE = 'modules/pipeline.py'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_O4zxFbKh6d",
        "outputId": "54e2b458-d862-4e99-d322-4b0ff39ff289"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting modules/pipeline.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile {PIPELINES_MODULE_FILE}\n",
        "\n",
        "from typing import Text\n",
        "\n",
        "from absl import logging\n",
        "from tfx.orchestration import metadata, pipeline\n",
        "\n",
        "\n",
        "def init_pipeline(pipeline_root: Text, pipeline_name, metadata_path, components):\n",
        "    \"\"\"Initiate tfx pipeline\n",
        "\n",
        "    Args:\n",
        "        pipeline_root (Text): a path to th pipeline directory\n",
        "        pipeline_name (str): pipeline name\n",
        "        metadata_path (str): a path to the metadata directory\n",
        "        components (dict): tfx components\n",
        "\n",
        "    Returns:\n",
        "        pipeline.Pipeline: pipeline orchestration\n",
        "    \"\"\"\n",
        "\n",
        "    logging.info(f\"Pipeline root set to: {pipeline_root}\")\n",
        "\n",
        "    beam_args = [\n",
        "        \"--direct_running_mode=multi_processing\",\n",
        "        \"----direct_num_workers=0\",\n",
        "    ]\n",
        "\n",
        "    return pipeline.Pipeline(\n",
        "        pipeline_name=pipeline_name,\n",
        "        pipeline_root=pipeline_root,\n",
        "        components=components,\n",
        "        enable_cache=True,\n",
        "        metadata_connection_config=metadata.sqlite_metadata_connection_config(\n",
        "            metadata_path,\n",
        "        ),\n",
        "        eam_pipeline_args=beam_args,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH_cfJBq24_e"
      },
      "source": [
        "## Run Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_vDJjgwo24b3"
      },
      "outputs": [],
      "source": [
        "#! pip install tfx tensorflow_model_analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "xf8_1Og924h1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\n",
        "from modules import components, pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b00_ES4V3FiQ"
      },
      "source": [
        "### Set Variabel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "IzTjFyIH3Cf-"
      },
      "outputs": [],
      "source": [
        "PIPELANE_NAME = \"purchase-predict-pipeline\"\n",
        "\n",
        "# Pipeline inputs\n",
        "DATA_ROOT = \"/content/data\"\n",
        "TRANSFORM_MODULE_FILE = \"modules/transform.py\"\n",
        "TUNER_MODULE_FILE = \"modules/tuner.py\"\n",
        "TRAINER_MODULE_FILE = \"modules/trainer.py\"\n",
        "\n",
        "# Pipeline outputs\n",
        "OUTPUT_BASE = \"outputs\"\n",
        "\n",
        "serving_model_dir = os.path.join(OUTPUT_BASE, \"serving_model\")\n",
        "pipeline_root = os.path.join(OUTPUT_BASE, PIPELANE_NAME)\n",
        "metadata_path = os.path.join(pipeline_root, \"metadata.sqlite\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVIv7NV23JzQ"
      },
      "source": [
        "### Menjalankan ML Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PE9YGj4l3Ci_",
        "outputId": "f816b47f-5abf-4bfb-a76b-813fb88bfe20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 10 Complete [00h 01m 23s]\n",
            "val_loss: 0.23939529061317444\n",
            "\n",
            "Best val_loss So Far: 0.23788103461265564\n",
            "Total elapsed time: 00h 06m 12s\n",
            "Results summary\n",
            "Results in outputs/purchase-predict-pipeline/Tuner/.system/executor_execution/21/.temp/21/kt_hyperband\n",
            "Showing 10 best trials\n",
            "<keras_tuner.engine.objective.Objective object at 0x7f47750e6eb0>\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_hidden_layers: 1\n",
            "dense_unit: 32\n",
            "dropout_rate: 0.40000000000000013\n",
            "learning_rate: 0.001\n",
            "tuner/epochs: 5\n",
            "tuner/initial_epoch: 2\n",
            "tuner/bracket: 1\n",
            "tuner/round: 1\n",
            "tuner/trial_id: 0000\n",
            "Score: 0.23788103461265564\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_hidden_layers: 3\n",
            "dense_unit: 512\n",
            "dropout_rate: 0.5500000000000002\n",
            "learning_rate: 0.001\n",
            "tuner/epochs: 5\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 0\n",
            "tuner/round: 0\n",
            "Score: 0.23939529061317444\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_hidden_layers: 3\n",
            "dense_unit: 64\n",
            "dropout_rate: 0.15000000000000002\n",
            "learning_rate: 0.001\n",
            "tuner/epochs: 2\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 1\n",
            "tuner/round: 0\n",
            "Score: 0.24364684522151947\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_hidden_layers: 3\n",
            "dense_unit: 64\n",
            "dropout_rate: 0.15000000000000002\n",
            "learning_rate: 0.001\n",
            "tuner/epochs: 5\n",
            "tuner/initial_epoch: 2\n",
            "tuner/bracket: 1\n",
            "tuner/round: 1\n",
            "tuner/trial_id: 0004\n",
            "Score: 0.24499782919883728\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_hidden_layers: 1\n",
            "dense_unit: 32\n",
            "dropout_rate: 0.40000000000000013\n",
            "learning_rate: 0.001\n",
            "tuner/epochs: 2\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 1\n",
            "tuner/round: 0\n",
            "Score: 0.24546949565410614\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_hidden_layers: 3\n",
            "dense_unit: 496\n",
            "dropout_rate: 0.15000000000000002\n",
            "learning_rate: 5e-06\n",
            "tuner/epochs: 5\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 0\n",
            "tuner/round: 0\n",
            "Score: 0.31782209873199463\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_hidden_layers: 3\n",
            "dense_unit: 352\n",
            "dropout_rate: 0.1\n",
            "learning_rate: 1e-05\n",
            "tuner/epochs: 2\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 1\n",
            "tuner/round: 0\n",
            "Score: 0.33182698488235474\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_hidden_layers: 3\n",
            "dense_unit: 224\n",
            "dropout_rate: 0.8000000000000002\n",
            "learning_rate: 0.01\n",
            "tuner/epochs: 2\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 1\n",
            "tuner/round: 0\n",
            "Score: 0.35763341188430786\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_hidden_layers: 3\n",
            "dense_unit: 448\n",
            "dropout_rate: 0.7000000000000002\n",
            "learning_rate: 1e-06\n",
            "tuner/epochs: 5\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 0\n",
            "tuner/round: 0\n",
            "Score: 0.37283965945243835\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_hidden_layers: 3\n",
            "dense_unit: 112\n",
            "dropout_rate: 0.5500000000000002\n",
            "learning_rate: 5e-06\n",
            "tuner/epochs: 2\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 1\n",
            "tuner/round: 0\n",
            "Score: 0.43466973304748535\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
            "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
            "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " eligible_xf (InputLayer)       [(None, 3)]          0           []                               \n",
            "                                                                                                  \n",
            " job_xf (InputLayer)            [(None, 13)]         0           []                               \n",
            "                                                                                                  \n",
            " marital_xf (InputLayer)        [(None, 4)]          0           []                               \n",
            "                                                                                                  \n",
            " education_xf (InputLayer)      [(None, 5)]          0           []                               \n",
            "                                                                                                  \n",
            " targeted_xf (InputLayer)       [(None, 3)]          0           []                               \n",
            "                                                                                                  \n",
            " default_xf (InputLayer)        [(None, 3)]          0           []                               \n",
            "                                                                                                  \n",
            " housing_xf (InputLayer)        [(None, 3)]          0           []                               \n",
            "                                                                                                  \n",
            " loan_xf (InputLayer)           [(None, 3)]          0           []                               \n",
            "                                                                                                  \n",
            " month_xf (InputLayer)          [(None, 13)]         0           []                               \n",
            "                                                                                                  \n",
            " age_xf (InputLayer)            [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " salary_xf (InputLayer)         [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " balance_xf (InputLayer)        [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " duration_xf (InputLayer)       [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " day_xf (InputLayer)            [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " campaign_xf (InputLayer)       [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " pdays_xf (InputLayer)          [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " previous_xf (InputLayer)       [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 58)           0           ['eligible_xf[0][0]',            \n",
            "                                                                  'job_xf[0][0]',                 \n",
            "                                                                  'marital_xf[0][0]',             \n",
            "                                                                  'education_xf[0][0]',           \n",
            "                                                                  'targeted_xf[0][0]',            \n",
            "                                                                  'default_xf[0][0]',             \n",
            "                                                                  'housing_xf[0][0]',             \n",
            "                                                                  'loan_xf[0][0]',                \n",
            "                                                                  'month_xf[0][0]',               \n",
            "                                                                  'age_xf[0][0]',                 \n",
            "                                                                  'salary_xf[0][0]',              \n",
            "                                                                  'balance_xf[0][0]',             \n",
            "                                                                  'duration_xf[0][0]',            \n",
            "                                                                  'day_xf[0][0]',                 \n",
            "                                                                  'campaign_xf[0][0]',            \n",
            "                                                                  'pdays_xf[0][0]',               \n",
            "                                                                  'previous_xf[0][0]']            \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 32)           1888        ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 32)           1056        ['dense_5[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 32)           0           ['dense_6[0][0]']                \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 1)            33          ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,977\n",
            "Trainable params: 2,977\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/2\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 0.2976 - binary_accuracy: 0.8955\n",
            "Epoch 1: val_binary_accuracy improved from -inf to 0.88799, saving model to outputs/purchase-predict-pipeline/Trainer/model/22/Format-Serving\n",
            "1000/1000 [==============================] - 9s 8ms/step - loss: 0.2983 - binary_accuracy: 0.8950 - val_loss: 0.3061 - val_binary_accuracy: 0.8880\n",
            "Epoch 2/2\n",
            " 995/1000 [============================>.] - ETA: 0s - loss: 0.2370 - binary_accuracy: 0.8949\n",
            "Epoch 2: val_binary_accuracy improved from 0.88799 to 0.89434, saving model to outputs/purchase-predict-pipeline/Trainer/model/22/Format-Serving\n",
            "1000/1000 [==============================] - 10s 10ms/step - loss: 0.2365 - binary_accuracy: 0.8952 - val_loss: 0.2702 - val_binary_accuracy: 0.8943\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "WARNING:tensorflow:`age group` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
            "WARNING:tensorflow:`age group` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.legacy.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7f47e0202460> and <keras.engine.input_layer.InputLayer object at 0x7f4773ebf190>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.legacy.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7f4773afbbb0> and <keras.engine.input_layer.InputLayer object at 0x7f4771ab8850>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.legacy.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7f4773939220> and <keras.engine.input_layer.InputLayer object at 0x7f4770e94310>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.legacy.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7f47e0069af0> and <keras.engine.input_layer.InputLayer object at 0x7f47700166d0>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.legacy.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7f4770cc2b80> and <keras.engine.input_layer.InputLayer object at 0x7f4771c42a00>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.legacy.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7f4770576f70> and <keras.engine.input_layer.InputLayer object at 0x7f47737cc190>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.legacy.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7f4770b0d640> and <keras.engine.input_layer.InputLayer object at 0x7f4770bf3430>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.legacy.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7f476e6a1fd0> and <keras.engine.input_layer.InputLayer object at 0x7f476e743190>).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow_model_analysis/writers/metrics_plots_and_validations_writer.py:110: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use eager execution and: \n",
            "`tf.data.TFRecordDataset(path)`\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n"
          ]
        }
      ],
      "source": [
        "components_args = {\n",
        "    \"data_dir\": DATA_ROOT,\n",
        "    \"trainer_module\": TRAINER_MODULE_FILE,\n",
        "    \"tuner_module\": TUNER_MODULE_FILE,\n",
        "    \"transform_module\": TRANSFORM_MODULE_FILE,\n",
        "    \"train_steps\": 1000,\n",
        "    \"eval_steps\": 800,\n",
        "    \"serving_model_dir\": serving_model_dir,\n",
        "}\n",
        "\n",
        "components = components.init_components(components_args)\n",
        "\n",
        "pipeline = pipeline.init_pipeline(\n",
        "    pipeline_root, \n",
        "    PIPELANE_NAME, \n",
        "    metadata_path, \n",
        "    components\n",
        ")\n",
        "BeamDagRunner().run(pipeline)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.5 (tags/v3.9.5:0a7dcbd, May  3 2021, 17:27:52) [MSC v.1928 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "08e595c52ca3b9470036b1110e67b559e55f367cabc363f2e28d35631ed95060"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
